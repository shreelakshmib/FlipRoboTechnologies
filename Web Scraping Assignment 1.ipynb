{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------\n",
    "1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "soup = BS(page.content,'html.parser')\n",
    "header_tags = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print(\"All Header Tags : \\n\")\n",
    "for each in header_tags:\n",
    "    print(each)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "page = requests.get(\"https://www.imdb.com/list/ls091520106/?sort=list_order,asc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp\")\n",
    "soup = BS(page.content,'html.parser')\n",
    "\n",
    "name = []\n",
    "rating = []\n",
    "release_year = []\n",
    "\n",
    "names = soup.find_all('span',class_ = 'lister-item-header')\n",
    "\n",
    "for x in names:\n",
    "    for y in x.find_all('a'):\n",
    "        name.append(y.get_text().replace(\"\\n\",\"\"))\n",
    "        \n",
    "ratings = soup.find_all('div',class_ = 'col-imdb-rating')\n",
    "for j in ratings:\n",
    "    for y in j.find_all('strong'):\n",
    "        rating .append(y.get_text().strip())  \n",
    "        \n",
    "year = soup.find_all('span',class_ = 'lister-item-year text-muted unbold')\n",
    "for k in year:\n",
    "    release_year.append(k.get_text().strip())\n",
    "\n",
    "imdb = pd.DataFrame({})\n",
    "imdb['Name'] = name\n",
    "imdb['IMDB Rating'] = rating\n",
    "imdb['Year of Release'] = release_year\n",
    "imdb.to_csv(\"Top100ImdbMoviesRatings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------\n",
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year\n",
    "of release) and save it in form of a CSV file.\n",
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.imdb.com/list/ls009997493/?sort=list_order,asc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp\")\n",
    "soup = BS(page.content,'html.parser')\n",
    "\n",
    "name = []\n",
    "rating = []\n",
    "release_year = []\n",
    "\n",
    "names = soup.find_all('span',class_ = 'lister-item-header')\n",
    "\n",
    "for x in names:\n",
    "    for y in x.find_all('a'):\n",
    "        name.append(y.get_text().replace(\"\\n\",\"\"))\n",
    "        \n",
    "ratings = soup.find_all('div',class_ = 'col-imdb-rating')\n",
    "for j in ratings:\n",
    "    for y in j.find_all('strong'):\n",
    "        rating .append(y.get_text().strip())  \n",
    "        \n",
    "year = soup.find_all('span',class_ = 'lister-item-year text-muted unbold')\n",
    "for k in year:\n",
    "    release_year.append(k.get_text().strip())\n",
    "\n",
    "imdb = pd.DataFrame({})\n",
    "imdb['Name'] = name\n",
    "imdb['IMDB Rating'] = rating\n",
    "imdb['Year of Release'] = release_year\n",
    "imdb.to_csv(\"Top100ImdbIndianMoviesRatings.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------\n",
    "4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://bookpage.com/reviews\")\n",
    "soup = BS(page.content,'html.parser')\n",
    "\n",
    "book = []\n",
    "author = []\n",
    "genre = []\n",
    "review = []\n",
    "\n",
    "bname = soup.find_all('h4','italic')\n",
    "aname = soup.find_all('p','sans bold')\n",
    "genres = soup.find_all('p','genre-links hidden-phone')\n",
    "reviews = soup.find_all('p','excerpt')\n",
    "\n",
    "count = 0\n",
    "for i in bname:\n",
    "    book.append(i.get_text().replace('\\n',''))\n",
    "    count = count+1\n",
    "    if count >= 5:\n",
    "        break\n",
    "count1 = 0\n",
    "for j in aname:\n",
    "    author.append(j.get_text().replace('\\n',''))\n",
    "    count1 = count1+1\n",
    "    if count1 >= 5:\n",
    "        break\n",
    "\n",
    "count2 = 0\n",
    "for k in genres:\n",
    "    genre.append(k.get_text().replace('\\n',''))\n",
    "    count2 = count2 + 1\n",
    "    if count2 >= 5:\n",
    "        break\n",
    "\n",
    "count3 = 0        \n",
    "for l in reviews:\n",
    "    review.append(l.get_text().replace('\\n',''))\n",
    "    count3 = count3+1\n",
    "    if count3 >= 5:\n",
    "        break\n",
    "    \n",
    "bookReviews = pd.DataFrame({})\n",
    "bookReviews['Book Name'] = book\n",
    "bookReviews['Author'] = author\n",
    "bookReviews['Genre'] = genre\n",
    "bookReviews['Reviews'] = review\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------\n",
    "5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (i) : Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "team_names = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "top_match = soup.find('td',class_='rankings-block__banner--matches')\n",
    "top_score = soup.find('td',class_='rankings-block__banner--points')\n",
    "top_rating = soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "\n",
    "matches.append(top_match.text)\n",
    "points.append(top_score.text)\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "team = soup.find_all('span',class_='u-hide-phablet')\n",
    "\n",
    "for each in range(len(team)):\n",
    "    team_names.append(team[each].get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "    \n",
    "match = soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in range(0,len(match)):\n",
    "    if (i%2 == 0):\n",
    "        matches.append(match[i].text)\n",
    "    else:\n",
    "        points.append(match[i].text)\n",
    "\n",
    "\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "teams_list = []\n",
    "matches_list = []\n",
    "points_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    teams_list.append(team_names[j])\n",
    "    matches_list.append(matches[j])\n",
    "    points_list.append(points[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(teams_list),len(matches_list),len(points_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",matches_list,\"\\n\",points_list,\"\\n\",ratings_list)    \n",
    "\n",
    "rankings = pd.DataFrame({})\n",
    "rankings['Teams'] = teams_list\n",
    "rankings['Matches'] = matches_list\n",
    "rankings['Points'] = points_list\n",
    "rankings['Ratings'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (men) ODI Teams\")\n",
    "print(\"-------------------------------------\")\n",
    "rankings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (ii) : Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "player_names = []\n",
    "team = []\n",
    "ratings = []\n",
    "\n",
    "top_player = soup.find('div',class_='rankings-block__banner--name')\n",
    "top_nationality = soup.find('div',class_='rankings-block__banner--nationality')\n",
    "top_rating = soup.find('div',class_='rankings-block__banner--rating')\n",
    "\n",
    "\n",
    "player_names.append(top_player.text)\n",
    "team.append(top_nationality.text.replace(\"\\n\",\"\"))\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "player = soup.find_all('td',class_='table-body__cell name')\n",
    "for each in player:\n",
    "    for i in each.find_all('a'):\n",
    "        player_names.append(i.text.strip())\n",
    "\n",
    "teams = soup.find_all('span',class_='table-body__logo-text')\n",
    "for each in (teams):\n",
    "    team.append(each.text.strip())\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "players_list = []\n",
    "teams_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    players_list.append(player_names[j])\n",
    "    teams_list.append(team[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(players_list),len(teams_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",player_names,\"\\n\",ratings_list)    \n",
    "\n",
    "batsmen = pd.DataFrame({})\n",
    "batsmen['Player'] = players_list\n",
    "batsmen['Team'] = teams_list\n",
    "batsmen['Rating'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (men) ODI Batsmen\")\n",
    "print(\"-------------------------------------\")\n",
    "batsmen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (iii) : Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "players_names = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "top_player = soup.find('div',class_='rankings-block__banner--name-large')\n",
    "top_nationality = soup.find('div',class_='rankings-block__banner--nationality')\n",
    "top_rating = soup.find('div',class_='rankings-block__banner--rating')\n",
    "\n",
    "\n",
    "players_names.append(top_player.text)\n",
    "teams.append(top_nationality.text.replace(\"\\n\",\"\"))\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "player = soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for each in player:\n",
    "    for i in each.find_all('a'):\n",
    "        players_names.append(i.text.strip())\n",
    "\n",
    "team = soup.find_all('span',class_='table-body__logo-text')\n",
    "for each in (team):\n",
    "    teams.append(each.text.strip())\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "players_list = []\n",
    "teams_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    players_list.append(players_names[j])\n",
    "    teams_list.append(teams[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(players_list),len(teams_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",player_names,\"\\n\",ratings_list)    \n",
    "\n",
    "bowlers = pd.DataFrame({})\n",
    "bowlers['Player'] = players_list\n",
    "bowlers['Team'] = teams_list\n",
    "bowlers['Rating'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (men) ODI Bowlers\")\n",
    "print(\"-------------------------------------\")\n",
    "bowlers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------\n",
    "6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (i) :  Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "team_names = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "top_match = soup.find('td',class_='rankings-block__banner--matches')\n",
    "top_score = soup.find('td',class_='rankings-block__banner--points')\n",
    "top_rating = soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "\n",
    "matches.append(top_match.text)\n",
    "points.append(top_score.text)\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "team = soup.find_all('span',class_='u-hide-phablet')\n",
    "\n",
    "for each in range(len(team)):\n",
    "    team_names.append(team[each].get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "    \n",
    "match = soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in range(0,len(match)):\n",
    "    if (i%2 == 0):\n",
    "        matches.append(match[i].text)\n",
    "    else:\n",
    "        points.append(match[i].text)\n",
    "\n",
    "\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "teams_list = []\n",
    "matches_list = []\n",
    "points_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    teams_list.append(team_names[j])\n",
    "    matches_list.append(matches[j])\n",
    "    points_list.append(points[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(teams_list),len(matches_list),len(points_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",matches_list,\"\\n\",points_list,\"\\n\",ratings_list)    \n",
    "\n",
    "rankings = pd.DataFrame({})\n",
    "rankings['Teams'] = teams_list\n",
    "rankings['Matches'] = matches_list\n",
    "rankings['Points'] = points_list\n",
    "rankings['Ratings'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (women) ODI Teams\")\n",
    "print(\"-------------------------------------\")\n",
    "rankings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (ii) : Top 10 women’s ODI players along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "players_names = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "top_player = soup.find('div',class_='rankings-block__banner--name-large')\n",
    "top_nationality = soup.find('div',class_='rankings-block__banner--nationality')\n",
    "top_rating = soup.find('div',class_='rankings-block__banner--rating')\n",
    "\n",
    "\n",
    "players_names.append(top_player.text)\n",
    "teams.append(top_nationality.text.replace(\"\\n\",\"\"))\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "player = soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for each in player:\n",
    "    for i in each.find_all('a'):\n",
    "        players_names.append(i.text.strip())\n",
    "\n",
    "team = soup.find_all('span',class_='table-body__logo-text')\n",
    "for each in (team):\n",
    "    teams.append(each.text.strip())\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "players_list = []\n",
    "teams_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    players_list.append(players_names[j])\n",
    "    teams_list.append(teams[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(players_list),len(teams_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",player_names,\"\\n\",ratings_list)    \n",
    "\n",
    "batswomen = pd.DataFrame({})\n",
    "batswomen['Player'] = players_list\n",
    "batswomen['Team'] = teams_list\n",
    "batswomen['Rating'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (women) ODI Players\")\n",
    "print(\"-------------------------------------\")\n",
    "batswomen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Part (iii) : Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "players_names = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "top_player = soup.find('div',class_='rankings-block__banner--name-large')\n",
    "top_nationality = soup.find('div',class_='rankings-block__banner--nationality')\n",
    "top_rating = soup.find('div',class_='rankings-block__banner--rating')\n",
    "\n",
    "\n",
    "players_names.append(top_player.text)\n",
    "teams.append(top_nationality.text.replace(\"\\n\",\"\"))\n",
    "ratings.append(top_rating.text.strip())\n",
    "\n",
    "player = soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for each in player:\n",
    "    for i in each.find_all('a'):\n",
    "        players_names.append(i.text.strip())\n",
    "\n",
    "team = soup.find_all('span',class_='table-body__logo-text')\n",
    "for each in (team):\n",
    "    teams.append(each.text.strip())\n",
    "\n",
    "rating = soup.find_all('td',class_='table-body__cell rating')\n",
    "for each in range(len(rating)):\n",
    "    ratings.append(rating[each].get_text().replace(\"\\n\",\"\").strip())\n",
    "    \n",
    "players_list = []\n",
    "teams_list = []\n",
    "ratings_list = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    players_list.append(players_names[j])\n",
    "    teams_list.append(teams[j])\n",
    "    ratings_list.append(ratings[j])\n",
    "\n",
    "#print(len(players_list),len(teams_list),len(ratings_list))\n",
    "#print(teams_list,\"\\n\",player_names,\"\\n\",ratings_list)    \n",
    "\n",
    "allRounder = pd.DataFrame({})\n",
    "allRounder['Teams'] = players_list\n",
    "allRounder['Matches'] = teams_list\n",
    "allRounder['Ratings'] = ratings_list\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  Top 10 (women) ODI all-rounders\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "allRounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The\n",
    "scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "\n",
    "driver  = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "\n",
    "products = []\n",
    "prices = []\n",
    "imageURLs = []\n",
    "ratings = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    url = \"https://www.amazon.in/s?k=mobile+phone+under+20000&page=\"+str(i)\n",
    "    driver.get(url)\n",
    "    \n",
    "   \n",
    "    product_list = driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "    for i in product_list:\n",
    "        products.append(i.text)\n",
    "\n",
    "    prices_list = driver.find_elements_by_xpath(\"//span[@class='a-price']/span[@class='a-offscreen']\")\n",
    "    for j in prices_list:\n",
    "        prices.append(j.get_attribute('innerHTML'))\n",
    "\n",
    "\n",
    "    ratings_list = driver.find_elements_by_xpath(\"//a[@class='a-popover-trigger a-declarative']/i/span\")\n",
    "    for l in ratings_list:\n",
    "        ratings.append(l.get_attribute('innerHTML'))\n",
    "\n",
    "\n",
    "    img_list = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-no-outline']/div/img\")\n",
    "    for k in img_list:\n",
    "        imageURLs.append(k.get_attribute(\"src\"))\n",
    "\n",
    "mobiles = pd.DataFrame({})\n",
    "mobiles[' Phone Name '] = products\n",
    "mobiles[' Image URL '] = imageURLs\n",
    "mobiles[' Ratings '] = ratings\n",
    "mobiles[' Cost '] = prices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "8. Write a python program to extract information about the local weather from the National Weather Service\n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day\n",
    "extended forecast display for the city. The data should include period, short description, temperature and\n",
    "description. \n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YAT01ugzbDc\"\n",
    "page = requests.get(url)\n",
    "soup = BS(page.content,\"html.parser\")\n",
    "\n",
    "period_list = []\n",
    "short_Desc = []\n",
    "temperature_list = []\n",
    "\n",
    "period = soup.find_all('p',class_='period-name')\n",
    "for i in range(1,len(period)):\n",
    "    period_list.append(period[i].text)\n",
    "    \n",
    "desc = soup.find_all('p',class_='short-desc')\n",
    "for j in range(1,len(desc)):\n",
    "    short_Desc.append(desc[j].text)\n",
    "               \n",
    "temp = soup.find_all('p',class_='temp')\n",
    "for each in temp:\n",
    "    temperature_list.append(each.text)\n",
    "    \n",
    "weather = pd.DataFrame({})\n",
    "weather['Period'] = period_list\n",
    "weather['Temperature'] = temperature_list\n",
    "weather['Description'] = short_Desc\n",
    "weather\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
