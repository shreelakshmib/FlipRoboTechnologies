{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task : To scrape web from EBM news archive from page 634 to 669 (2019) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "content = []\n",
    "\n",
    "year = 2019\n",
    "start_page_number = 634\n",
    "end_page_number = 669\n",
    "for i in range(start_page_number,end_page_number+1):\n",
    "    number = i\n",
    "    url = \"https://www.ebmnews.com/\"+str(year)+\"/page/\"+str(number)+\"/\"\n",
    "    \n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "                                                                                       \n",
    "    news_title = [j.get_attribute('href') for j in driver.find_elements_by_xpath(\"//*[@id='content']/div/div/div[1]/div[1]/article/div/h2/a\")]\n",
    "    \n",
    "    for news in news_title:\n",
    "        driver.get(news)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        title = driver.find_elements_by_xpath(\"//div[@class='post-header post-tp-1-header']/h1/span\")\n",
    "        for t in title:\n",
    "            title_list.append(t.text)\n",
    "        data = driver.find_elements_by_xpath(\"//div[@class='entry-content clearfix single-post-content']\")\n",
    "        for d in data:\n",
    "            news = d.get_attribute('innerHTML').strip().replace(\"<p>\",\"\")\n",
    "            content.append(news.replace(\"</p>\\n\",\"\").replace(\"<br>\\n\",\"\").replace(\"</p>\",\"\"))\n",
    "driver.close()\n",
    "\n",
    "news_dataset = pd.DataFrame({'Title':title_list,\n",
    "                             'News Content':content})\n",
    "            \n",
    "\n",
    "news_dataset.to_csv(\"News Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
