{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data from  https://www.naukri.com/\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp;amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immediate openings For MIS executive /Data ana...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mumbai, Bengaluru, Hyderabad</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>St. John’s Research Institute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Siemens Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Procurement Data Analyst ( 0.6 To 3 Yrs, Banga...</td>\n",
       "      <td>Bengaluru(Koramangala)</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Sunstream Global Technologies LLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Security Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Philips India Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru, Kolkata</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  Immediate openings For MIS executive /Data ana...   \n",
       "2                                       Data Analyst   \n",
       "3  MIS/ Data Analyst-(SQL,Automation,Excel/PowerB...   \n",
       "4                                       Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6  Procurement Data Analyst ( 0.6 To 3 Yrs, Banga...   \n",
       "7                                       Data Analyst   \n",
       "8                              Security Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                          Job Location Experience Required  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad             0-3 Yrs   \n",
       "1                            Bengaluru             3-8 Yrs   \n",
       "2         Mumbai, Bengaluru, Hyderabad             2-3 Yrs   \n",
       "3                            Bengaluru             1-4 Yrs   \n",
       "4                            Bengaluru             0-4 Yrs   \n",
       "5                            Bengaluru             0-3 Yrs   \n",
       "6               Bengaluru(Koramangala)             0-3 Yrs   \n",
       "7                            Bengaluru             4-6 Yrs   \n",
       "8                            Bengaluru             2-4 Yrs   \n",
       "9                   Bengaluru, Kolkata             3-4 Yrs   \n",
       "\n",
       "                                             Company  \n",
       "0  CAIA-Center For Artificial Intelligence &amp; ...  \n",
       "1                             RANDSTAD INDIA PVT LTD  \n",
       "2       Cognizant Technology Solutions India Pvt Ltd  \n",
       "3                  Flipkart Internet Private Limited  \n",
       "4                      St. John’s Research Institute  \n",
       "5                                    Siemens Limited  \n",
       "6                  Sunstream Global Technologies LLP  \n",
       "7                             IBM India Pvt. Limited  \n",
       "8                              Philips India Limited  \n",
       "9       Cognizant Technology Solutions India Pvt Ltd  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function definition\n",
    "def find_jobs_from(url) :\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    skill_field = driver.find_element_by_name('keyword')\n",
    "    skill_field.send_keys(\"Data Analyst\")\n",
    "\n",
    "    location_field = driver.find_element_by_name('location')\n",
    "    location_field.send_keys(\"Bangalore\")\n",
    "\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    try:\n",
    "        search_button.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    driver.get(current_url)\n",
    "\n",
    "    job_title = []\n",
    "    job_location = []\n",
    "    company_name = []\n",
    "    experience_required = []\n",
    "\n",
    "    jobs = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    for i in range(0,len(jobs)):\n",
    "        if i < 10:\n",
    "            try:\n",
    "                job_title.append(jobs[i].text)\n",
    "            except NoSuchElementException:\n",
    "                job_title.append(\" -- \")\n",
    "\n",
    "    locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    for j in range(0,len(locations)):\n",
    "        if j < 10:\n",
    "            try:\n",
    "                job_location.append(locations[j].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                job_location.append(\" -- \")\n",
    "\n",
    "    experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    for k in range(0,len(experience)):\n",
    "        if k < 10 :\n",
    "            try:\n",
    "                experience_required.append(experience[k].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                experience_required.append(\" -- \")\n",
    "\n",
    "    company = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    for l in range(0,len(company)):\n",
    "        if l < 10 :\n",
    "            try:\n",
    "                company_name.append(company[l].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                company_name.append(\" -- \")\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "    data_analyst_jobs = pd.DataFrame({\"Job Title\" : job_title,\n",
    "                                      'Job Location' : job_location,\n",
    "                                      'Experience Required' : experience_required,\n",
    "                                      'Company' : company_name\n",
    "                                     })\n",
    "    return data_analyst_jobs\n",
    "\n",
    "#Call Function\n",
    "df = find_jobs_from(\"https://www.naukri.com/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data from https://www.naukri.com/.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp;amp; ...</td>\n",
       "      <td>Dear Candidate  Schedule a Telephonic Intervi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>Dear Candidate,  Greetings from HCL!!! We are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist - Machine/Deep Learni...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Fidius advisory</td>\n",
       "      <td>Job Description : - We are looking for a rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Key Responsibilities Be responsible for scal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Roles and Responsibilities We are looking for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai, Bhubaneshwar, Pune, Delhi NCR, Mumbai...</td>\n",
       "      <td>Mailkit Private Limited</td>\n",
       "      <td>Mailkit is an European Marketing Automation c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Complete Remote Work</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Techolution India Private Limited</td>\n",
       "      <td>We are looking for qualified Lead Data Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Introduction The Data Scientist actively part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  HCL hiring Data scientist with exp in machine ...   \n",
       "2                   Data Scientist -Machine Learning   \n",
       "3  Principal Data Scientist - Machine/Deep Learni...   \n",
       "4                       Senior / Lead Data Scientist   \n",
       "5    Data Scientist - Machine Learning (Commerce BU)   \n",
       "6  Software Developer - Data Scientist / NLP / Ma...   \n",
       "7                                     Data Scientist   \n",
       "8         Lead Data Scientist - Complete Remote Work   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                           Chennai, Pune, Bengaluru   \n",
       "5                                          Bengaluru   \n",
       "6                              Bengaluru / Bangalore   \n",
       "7  Chennai, Bhubaneshwar, Pune, Delhi NCR, Mumbai...   \n",
       "8  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                             Company  \\\n",
       "0  CAIA-Center For Artificial Intelligence &amp; ...   \n",
       "1                           HCL Technologies Limited   \n",
       "2                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "3                                    Fidius advisory   \n",
       "4                        TVS CREDIT SERVICES LIMITED   \n",
       "5                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "6                     Cunesoft India Private Limited   \n",
       "7                            Mailkit Private Limited   \n",
       "8                  Techolution India Private Limited   \n",
       "9                             IBM India Pvt. Limited   \n",
       "\n",
       "                                     Job Description  \n",
       "0   Dear Candidate  Schedule a Telephonic Intervi...  \n",
       "1   Dear Candidate,  Greetings from HCL!!! We are...  \n",
       "2                                                 --  \n",
       "3   Job Description : - We are looking for a rese...  \n",
       "4    Key Responsibilities Be responsible for scal...  \n",
       "5                                                 --  \n",
       "6   Roles and Responsibilities We are looking for...  \n",
       "7   Mailkit is an European Marketing Automation c...  \n",
       "8    We are looking for qualified Lead Data Scien...  \n",
       "9   Introduction The Data Scientist actively part...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function definition\n",
    "def find_jobs_from(url) :\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    skill_field = driver.find_element_by_name('keyword')\n",
    "    skill_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "    location_field = driver.find_element_by_name('location')\n",
    "    location_field.send_keys(\"Bangalore\")\n",
    "\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    try:\n",
    "        search_button.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    driver.get(current_url)\n",
    "\n",
    "    job_title = []\n",
    "    job_location = []\n",
    "    company_name = []\n",
    "    description = []\n",
    "\n",
    "    jobs = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    for i in range(0,len(jobs)):\n",
    "        if i < 10:\n",
    "            try:\n",
    "                job_title.append(jobs[i].text)\n",
    "            except NoSuchElementException:\n",
    "                job_title.append(\" -- \")\n",
    "\n",
    "    locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    for j in range(0,len(locations)):\n",
    "        if j < 10:\n",
    "            try:\n",
    "                job_location.append(locations[j].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                job_location.append(\" -- \")\n",
    "\n",
    "    company = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    for l in range(0,len(company)):\n",
    "        if l < 10 :\n",
    "            try:\n",
    "                company_name.append(company[l].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                company_name.append(\" -- \")\n",
    "                \n",
    "    desc_url = []\n",
    "    description_url = driver.find_elements_by_xpath(\"//div[@class='info fleft']/a\")\n",
    "    for k in range(0,len(description_url)):\n",
    "        if k < 10 :\n",
    "            desc_url.append(description_url[k].get_attribute('href'))\n",
    "        \n",
    "    for each in desc_url:\n",
    "        try:\n",
    "            driver.get(each)\n",
    "            desc = driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "            description.append(desc.text.replace(\"Job description\",\"\").replace(\"\\n\",\" \"))\n",
    "        except NoSuchElementException:\n",
    "            description.append(\"--\")\n",
    "\n",
    " \n",
    "    driver.close()\n",
    "\n",
    "\n",
    "    data_analyst_jobs = pd.DataFrame({\"Job Title\" : job_title,\n",
    "                                      'Job Location' : job_location,\n",
    "                                      'Company' : company_name,\n",
    "                                      'Job Description' : description\n",
    "                                     })\n",
    "    return data_analyst_jobs\n",
    "\n",
    "#Call Function\n",
    "df = pd.DataFrame()\n",
    "df = find_jobs_from(\"https://www.naukri.com/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "Q3. Find job-title, job-location, company_name, and experience_required. You have to scrape first 10 jobs data from \n",
    "https://www.naukri.com/ .The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Computer Vision</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Bengaluru, Hyderabad, Gurgaon</td>\n",
       "      <td>PEOPLE STAFFING SOLUTIONS</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Tableau/Power BI</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Talent Stock Solutions</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - IT</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Ehireo</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1            Senior Data Scientist - Computer Vision   \n",
       "2             Data Scientist - Machine Learning/ NLP   \n",
       "3                                     Data Scientist   \n",
       "4                  Data Scientist - Tableau/Power BI   \n",
       "5  GCP Skilled Analytics Resources (Data engineer...   \n",
       "6           Data Scientist - Python/Machine Learning   \n",
       "7                                Data Scientist - IT   \n",
       "8                                     Data Scientist   \n",
       "9                    Data Scientist Machine Learning   \n",
       "\n",
       "                          Job Location                             Company  \\\n",
       "0      Faridabad, Delhi NCR, Ghaziabad                    Amity University   \n",
       "1                            Delhi NCR                   IRIS SOFTWARE Inc   \n",
       "2                     Gurgaon Gurugram                              TalPro   \n",
       "3  Pune, Bengaluru, Hyderabad, Gurgaon          PEOPLE STAFFING SOLUTIONS    \n",
       "4                                Delhi              Talent Stock Solutions   \n",
       "5             Pune, Bengaluru, Gurgaon  Aerial Telecom Solutions Pvt. Ltd.   \n",
       "6                                Noida                               Jubna   \n",
       "7                              Gurgaon                              Ehireo   \n",
       "8                     Gurgaon Gurugram              IBM India Pvt. Limited   \n",
       "9                              Gurgaon                           Delhivery   \n",
       "\n",
       "  Experience Required  \n",
       "0             6-8 Yrs  \n",
       "1             4-9 Yrs  \n",
       "2             2-6 Yrs  \n",
       "3             3-6 Yrs  \n",
       "4             1-3 Yrs  \n",
       "5             3-8 Yrs  \n",
       "6             5-8 Yrs  \n",
       "7             4-9 Yrs  \n",
       "8             3-5 Yrs  \n",
       "9             1-3 Yrs  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_jobs_from(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    skill_field = driver.find_element_by_name('keyword')\n",
    "    skill_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "    search_button = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    try:\n",
    "        search_button.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "    salary = ''\n",
    "    title = '' \n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//span[@title='Delhi/NCR']\").click()\n",
    "        time.sleep(2)\n",
    "        driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\").click()\n",
    "        time.sleep(2)\n",
    "\n",
    "    except ElementNotInteractableException as err:\n",
    "        print(err)\n",
    "\n",
    "    job_titles = []\n",
    "    job_locations = []\n",
    "    job_experiences = []\n",
    "    company_names = []\n",
    "\n",
    "    jobs = driver.find_elements_by_xpath(\"//div[@class='info fleft']/a\")\n",
    "    for i in range(0,len(jobs)):\n",
    "        if i < 10:\n",
    "            try:\n",
    "                job_titles.append(jobs[i].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                job_titles.append(\" -- \")\n",
    "\n",
    "\n",
    "    locations = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    for j in range(0,len(locations)):\n",
    "        if j < 10:\n",
    "            try:\n",
    "                job_locations.append(locations[j].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                job_locations.append(\" -- \")\n",
    "\n",
    "    experience = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "    for k in range(0,len(experience)):\n",
    "        if k < 10 :\n",
    "            try:\n",
    "                job_experiences.append(experience[k].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                job_experiences.append(\" -- \")\n",
    "\n",
    "    company = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    for l in range(0,len(company)):\n",
    "        if l < 10 :\n",
    "            try:\n",
    "                company_names.append(company[l].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                company_names.append(\" -- \")\n",
    "\n",
    "    data_scientist_jobs = pd.DataFrame({\"Job Title\" : job_titles,\n",
    "                                      'Job Location' : job_locations,\n",
    "                                      'Company' : company_names,\n",
    "                                      'Experience Required': job_experiences\n",
    "                                     })\n",
    "    return data_scientist_jobs\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "df = find_jobs_from(\"https://www.naukri.com/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "Q5: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location from https://www.glassdoor.co.in/Salaries/index.htm. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Number of Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13</td>\n",
       "      <td>₹456K</td>\n",
       "      <td>₹11,789K</td>\n",
       "      <td>₹ 12,81,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>11</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,636K</td>\n",
       "      <td>₹ 7,52,052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10</td>\n",
       "      <td>₹585K</td>\n",
       "      <td>₹2,200K</td>\n",
       "      <td>₹ 9,98,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>9</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,024K</td>\n",
       "      <td>₹ 6,02,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>9</td>\n",
       "      <td>₹595K</td>\n",
       "      <td>₹2,769K</td>\n",
       "      <td>₹ 7,71,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>9</td>\n",
       "      <td>₹727K</td>\n",
       "      <td>₹1,597K</td>\n",
       "      <td>₹ 13,55,346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8</td>\n",
       "      <td>₹509K</td>\n",
       "      <td>₹1,168K</td>\n",
       "      <td>₹ 7,91,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7</td>\n",
       "      <td>₹629K</td>\n",
       "      <td>₹1,719K</td>\n",
       "      <td>₹ 12,15,138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6</td>\n",
       "      <td>₹804K</td>\n",
       "      <td>₹1,281K</td>\n",
       "      <td>₹ 10,21,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5</td>\n",
       "      <td>₹205K</td>\n",
       "      <td>₹1,835K</td>\n",
       "      <td>₹ 10,00,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company Number of Salary Minimum Salary  \\\n",
       "0                       Delhivery              13           ₹456K   \n",
       "1              Ericsson-Worldwide              11           ₹420K   \n",
       "2                       Accenture              10           ₹585K   \n",
       "3       Tata Consultancy Services               9           ₹336K   \n",
       "4                             IBM               9           ₹595K   \n",
       "5              UnitedHealth Group               9           ₹727K   \n",
       "6              Valiance Solutions               8           ₹509K   \n",
       "7                      Innovaccer               7           ₹629K   \n",
       "8  Cognizant Technology Solutions               6           ₹804K   \n",
       "9                   ZS Associates               5           ₹205K   \n",
       "\n",
       "  Maximum Salary Average Salary  \n",
       "0       ₹11,789K    ₹ 12,81,419  \n",
       "1        ₹1,636K     ₹ 7,52,052  \n",
       "2        ₹2,200K     ₹ 9,98,925  \n",
       "3        ₹1,024K     ₹ 6,02,000  \n",
       "4        ₹2,769K     ₹ 7,71,657  \n",
       "5        ₹1,597K    ₹ 13,55,346  \n",
       "6        ₹1,168K     ₹ 7,91,015  \n",
       "7        ₹1,719K    ₹ 12,15,138  \n",
       "8        ₹1,281K    ₹ 10,21,889  \n",
       "9        ₹1,835K    ₹ 10,00,000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_jobs_from(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    skill_field = driver.find_element_by_class_name('keyword')\n",
    "    skill_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "    location_field = driver.find_element_by_class_name('loc')\n",
    "    location_field.send_keys(Keys.CONTROL + \"a\")\n",
    "    location_field.send_keys(Keys.DELETE)\n",
    "\n",
    "    location_field.send_keys(\"Noida\")\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "    try:\n",
    "        search_button.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "\n",
    "    min_salary = []\n",
    "    max_salary = []\n",
    "    avg_salary = []\n",
    "    company_name = []\n",
    "    number_of_salary = []\n",
    "\n",
    "    time.sleep(2)\n",
    "    min_sal  = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "    for i in range(0,len(min_sal)):\n",
    "        if i < 10:\n",
    "            try:\n",
    "                min_salary.append(min_sal[i].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException as Err:\n",
    "                min_salary.append(\" -- \")\n",
    "\n",
    "    max_sal  = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "    for j in range(0,len(max_sal)):\n",
    "        if j < 10:\n",
    "            try:\n",
    "                max_salary.append(max_sal[j].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException as Err:\n",
    "                max_salary.append(\" -- \")\n",
    "\n",
    "    avg_sal  = driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "    for k in range(0,len(avg_sal)):\n",
    "        if k < 10:\n",
    "            try:\n",
    "                avg_salary.append(avg_sal[k].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException as Err:\n",
    "                avg_salary.append(\" -- \")\n",
    "\n",
    "    number  = driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "    for l in range(0,len(number)):\n",
    "        if l < 10:\n",
    "            try:\n",
    "                num = number[l].text.strip().replace(\"salaries\",\"\")\n",
    "                number_of_salary.append(num)\n",
    "            except NoSuchElementException as Err:\n",
    "                number_of_salary.append(\" -- \")\n",
    "\n",
    "    company = driver.find_elements_by_xpath(\"//p[@class='m-0 ']\")\n",
    "    for m in range(0,len(company)):\n",
    "        if m < 10 :\n",
    "            try:\n",
    "                company_name.append(company[m].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException as err:\n",
    "                company_name.append(\" -- \")\n",
    "    \n",
    "    data_scientist_jobs = pd.DataFrame({\"Company\" : company_name,\n",
    "                                      'Number of Salary' : number_of_salary,\n",
    "                                      'Minimum Salary' : min_salary,\n",
    "                                      'Maximum Salary' : max_salary,\n",
    "                                      'Average Salary': avg_salary\n",
    "                                     })\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "    return data_scientist_jobs\n",
    "    \n",
    "    \n",
    "\n",
    "df = find_jobs_from(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "Q6. Scrape following data for first 100 Sunglasses : Brand,Product,price and discount%.\n",
    "\n",
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estillarse</td>\n",
       "      <td>Gradient Aviator Sunglasses (55)</td>\n",
       "      <td>₹280</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹239</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like future</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹181</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹708</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹1,650</td>\n",
       "      <td>17% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>JOHAENA</td>\n",
       "      <td>Night Vision Spectacle , Sports Sunglasses (50)</td>\n",
       "      <td>₹149</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Estillarse</td>\n",
       "      <td>Gradient Aviator Sunglasses (55)</td>\n",
       "      <td>₹280</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product Description  \\\n",
       "0         Estillarse                   Gradient Aviator Sunglasses (55)   \n",
       "1          ROYAL SON         UV Protection Retro Square Sunglasses (88)   \n",
       "2         Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "3   shah collections  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "4        like future            Mirrored Aviator Sunglasses (Free Size)   \n",
       "..               ...                                                ...   \n",
       "95          Fastrack        UV Protection Shield Sunglasses (Free Size)   \n",
       "96          Fastrack        Gradient Rectangular Sunglasses (Free Size)   \n",
       "97           JOHAENA    Night Vision Spectacle , Sports Sunglasses (50)   \n",
       "98         Rich Club                UV Protection Round Sunglasses (50)   \n",
       "99        Estillarse                   Gradient Aviator Sunglasses (55)   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹280  37% off  \n",
       "1     ₹599  70% off  \n",
       "2     ₹379  81% off  \n",
       "3     ₹239  76% off  \n",
       "4     ₹181  83% off  \n",
       "..     ...      ...  \n",
       "95    ₹708  21% off  \n",
       "96  ₹1,650  17% off  \n",
       "97    ₹149  86% off  \n",
       "98    ₹379  62% off  \n",
       "99    ₹280  37% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sunglass(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #close pop_up\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    search = driver.find_element_by_xpath(\"//*[@placeholder='Search for products, brands and more']\")\n",
    "    search.send_keys(\"Sunglasses\")\n",
    "\n",
    "\n",
    "    search = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    try:\n",
    "        search.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "\n",
    "\n",
    "    brands = []\n",
    "    products = []\n",
    "    prices = []\n",
    "    discount_percentages = []\n",
    "    urls = []\n",
    "\n",
    "    start_page=0\n",
    "    end_page=2\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "    \n",
    "    #Find all urls for 3 pages\n",
    "    soup = BS(driver.page_source,'html.parser')\n",
    "    url = soup.find_all('a',class_=\"ge-49M\")\n",
    "    for each in url[start_page:end_page+1]:\n",
    "        urls.append(\"https://www.flipkart.com\"+each.get('href'))\n",
    "\n",
    "    for i in urls:\n",
    "        driver.get(i)\n",
    "        brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        for j in range(0,len(brand)):\n",
    "            try:\n",
    "                if len(brands) != 100:\n",
    "                    brands.append(brand[j].text)\n",
    "            except NoSuchElementException:\n",
    "                brands.append(\" -- \")\n",
    "\n",
    "        product = driver.find_elements_by_xpath(\"//a[contains(@class,'IRpwTa') or contains(@class,'IRpwTa _2-ICcC')]\")\n",
    "        for k in range(0,len(product)):\n",
    "            try:\n",
    "                if len(products) != 100:\n",
    "                    products.append(product[k].text)\n",
    "            except NoSuchElementException:\n",
    "                product.append(\" -- \")\n",
    "\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "        for l in range(0,len(price)):\n",
    "            try:\n",
    "                if len(prices) != 100:\n",
    "                    prices.append(price[l].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                prices.append(\" -- \")\n",
    "\n",
    "        percentage = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "        for m in range(0,len(percentage)):\n",
    "            try:\n",
    "                if len(discount_percentages) != 100:\n",
    "                    discount_percentages.append(percentage[m].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                discount_percentages.append(\" -- \")\n",
    "                \n",
    "    \n",
    "    sunglasses = pd.DataFrame({\"Brand\" : brands,\n",
    "                                      'Product Description' : products,\n",
    "                                      'Price' : prices,\n",
    "                                      'Discount' : discount_percentages\n",
    "\n",
    "                                     })\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "    return sunglasses\n",
    "\n",
    "\n",
    "df = sunglass(\"https://www.flipkart.com/\")\n",
    "df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Seller - SuperComNet ( my trust in you has gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Have used both iPhone X and iPhone XR and I ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>The phone is awesome undoubtedly and worth the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Switched from Android to Iphone. great experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Iphone 11 black 64gb is really a cool phone\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings      Review Summary  \\\n",
       "0        5    Perfect product!   \n",
       "1        5       Great product   \n",
       "2        5  Highly recommended   \n",
       "3        5    Perfect product!   \n",
       "4        5    Perfect product!   \n",
       "..     ...                 ...   \n",
       "95       5           Excellent   \n",
       "96       5            Terrific   \n",
       "97       3        Does the job   \n",
       "98       5            Terrific   \n",
       "99       3                Nice   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95  Seller - SuperComNet ( my trust in you has gro...  \n",
       "96  Have used both iPhone X and iPhone XR and I ca...  \n",
       "97  The phone is awesome undoubtedly and worth the...  \n",
       "98  Switched from Android to Iphone. great experie...  \n",
       "99  Iphone 11 black 64gb is really a cool phone\\n\\...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iphone(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    #View all reviews :\n",
    "    reviews = driver.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\").get_attribute('href')\n",
    "    time.sleep(0.5)\n",
    "    driver.get(reviews)\n",
    "\n",
    "    ratings = []\n",
    "    review_summary = []\n",
    "    full_review = []\n",
    "\n",
    "    urls=[]\n",
    "    \n",
    "    start_page = 1\n",
    "    end_page = 10\n",
    "\n",
    "    #Find all urls for 10 pages\n",
    "    soup = BS(driver.page_source,'html.parser')\n",
    "    url = soup.find_all('a',class_='ge-49M')\n",
    "    current_url = driver.current_url\n",
    "    urls.append(current_url)\n",
    "    for each in url[start_page:end_page+1]:\n",
    "        urls.append(\"https://www.flipkart.com\"+each.get('href'))\n",
    "\n",
    "    for every_url in urls:\n",
    "        driver.get(every_url)\n",
    "        \n",
    "        rating = driver.find_elements_by_xpath(\"//div[contains(@class,'_3LWZlK _1BLPMq') or contains(@class,'_3LWZlK _1rdVr6 _1BLPMq')]\")\n",
    "        for each in rating:\n",
    "            try:\n",
    "                if len(ratings) != 100:\n",
    "                    ratings.append(each.get_attribute('innerHTML').split(\"<\")[0])\n",
    "            except NoSuchElementException:\n",
    "                ratings.append(\"--\")\n",
    "\n",
    "        summary = driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for each in summary:\n",
    "            try:\n",
    "                if len(review_summary) != 100:\n",
    "                    review_summary.append(each.text)\n",
    "            except NoSuchElementException:\n",
    "                review_summary.append(\"--\")\n",
    "\n",
    "        full_reviews = driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for each in full_reviews:\n",
    "            try:\n",
    "                if len(full_review) != 100:\n",
    "                    full_review.append(each.text)\n",
    "            except NoSuchElementException:\n",
    "                full_review.append(\"--\")\n",
    "                \n",
    "    \n",
    "    \n",
    "    iphone_reviews = pd.DataFrame({'Ratings' : ratings,\n",
    "                                   'Review Summary' : review_summary,\n",
    "                                   'Full Review' : full_review\n",
    "                                  })\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return iphone_reviews\n",
    "\n",
    "        \n",
    "df = iphone(url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------\n",
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arivo</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Lac...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>516 Sneakers For Men</td>\n",
       "      <td>₹420</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANPATI TRADERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹229</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ktiz</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>22% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹240</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>SM-482 Sneakers For Men</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>516 Sneakers For Men</td>\n",
       "      <td>₹420</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product Description  \\\n",
       "0                 Arivo  Fashion Outdoor Canvas Casual Light Weight Lac...   \n",
       "1                Chevit                               516 Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4   World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "..                  ...                                                ...   \n",
       "95      GANPATI TRADERS                                   Sneakers For Men   \n",
       "96                 Ktiz                                   Sneakers For Men   \n",
       "97  World Wear Footwear                                   Sneakers For Men   \n",
       "98                Sparx                            SM-482 Sneakers For Men   \n",
       "99               Chevit                               516 Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹449  65% off  \n",
       "1     ₹420  47% off  \n",
       "2     ₹499  75% off  \n",
       "3     ₹378  62% off  \n",
       "4     ₹499  75% off  \n",
       "..     ...      ...  \n",
       "95    ₹229  51% off  \n",
       "96    ₹449  22% off  \n",
       "97    ₹240  47% off  \n",
       "98  ₹1,049  60% off  \n",
       "99    ₹420  36% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sneakers(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #close pop_up\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    search = driver.find_element_by_xpath(\"//*[@placeholder='Search for products, brands and more']\")\n",
    "    search.send_keys(\"Sneakers\")\n",
    "\n",
    "\n",
    "    search = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    try:\n",
    "        search.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "\n",
    "\n",
    "    brands = []\n",
    "    products = []\n",
    "    prices = []\n",
    "    discount_percentages = []\n",
    "    urls = []\n",
    "\n",
    "    start_page=0\n",
    "    end_page=2\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "    \n",
    "    #Find all urls for 3 pages\n",
    "    soup = BS(driver.page_source,'html.parser')\n",
    "    url = soup.find_all('a',class_=\"ge-49M\")\n",
    "    for each in url[start_page:end_page+1]:\n",
    "        urls.append(\"https://www.flipkart.com\"+each.get('href'))\n",
    "\n",
    "    for i in urls:\n",
    "        driver.get(i)\n",
    "        brand = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        for j in range(0,len(brand)):\n",
    "            try:\n",
    "                if len(brands) != 100:\n",
    "                    brands.append(brand[j].text)\n",
    "            except NoSuchElementException:\n",
    "                brands.append(\" -- \")\n",
    "\n",
    "        product = driver.find_elements_by_xpath(\"//a[contains(@class,'IRpwTa') or contains(@class,'IRpwTa _2-ICcC')]\")\n",
    "        for k in range(0,len(product)):\n",
    "            try:\n",
    "                if len(products) != 100:\n",
    "                    products.append(product[k].text)\n",
    "            except NoSuchElementException:\n",
    "                product.append(\" -- \")\n",
    "\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "        for l in range(0,len(price)):\n",
    "            try:\n",
    "                if len(prices) != 100:\n",
    "                    prices.append(price[l].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                prices.append(\" -- \")\n",
    "\n",
    "        percentage = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "        for m in range(0,len(percentage)):\n",
    "            try:\n",
    "                if len(discount_percentages) != 100:\n",
    "                    discount_percentages.append(percentage[m].get_attribute('innerHTML'))\n",
    "            except NoSuchElementException:\n",
    "                discount_percentages.append(\" -- \")\n",
    "                \n",
    "    \n",
    "    sunglasses = pd.DataFrame({\"Brand\" : brands,\n",
    "                                      'Product Description' : products,\n",
    "                                      'Price' : prices,\n",
    "                                      'Discount' : discount_percentages\n",
    "\n",
    "                                     })\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "    return sunglasses\n",
    "\n",
    "\n",
    "df = find_sneakers(\"https://www.flipkart.com/\")\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------\n",
    "Q9. Go to the link - https://www.myntra.com/shoes. Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”. \n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description and price of the shoe\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Price (in Rs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women PEGASUS 37 Running Shoes</td>\n",
       "      <td>7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>11156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vans</td>\n",
       "      <td>Men Striped Sneakers</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Heels</td>\n",
       "      <td>6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Leather Pumps</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Heritage Leather Sneakers</td>\n",
       "      <td>7199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                    Descriptions Price (in Rs)\n",
       "0                   Nike  Women PEGASUS 37 Running Shoes          7496\n",
       "1                   Nike     Men JORDAN DELTA Basketball         12495\n",
       "2                   Nike      Men React Infinity Running         11156\n",
       "3                   Nike       Men JORDAN DELTA Sneakers         10995\n",
       "4                   Nike       Women REACT Running Shoes          8636\n",
       "..                   ...                             ...           ...\n",
       "95                  Vans            Men Striped Sneakers          9999\n",
       "96        Tommy Hilfiger              Men Solid Sneakers          7199\n",
       "97  Heel & Buckle London       Women Solid Leather Heels          6993\n",
       "98                  Geox       Women Solid Leather Pumps          6999\n",
       "99        Tommy Hilfiger   Men Heritage Leather Sneakers          7199\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_shoes(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    #Filter : Price Range : Rs 5899 - Rs 11599\n",
    "    driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\").click()\n",
    "    time.sleep(1)\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "    #Filter : Color : Black\n",
    "    driver.find_element_by_xpath(\"//*[@id='mountRoot']/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\").click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    start_page = 0\n",
    "    end_page = 1\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "\n",
    "    brands = []\n",
    "    descriptions = []\n",
    "    prices = []\n",
    "\n",
    "    for p in range(start_page,end_page+1):\n",
    "        brand = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "        for i in brand:\n",
    "            try:\n",
    "                if len(brands) != 100:\n",
    "                    brands.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                brands.append(\" -- \")\n",
    "\n",
    "        desc =  driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "        for m in desc:\n",
    "            try:\n",
    "                if len(descriptions) != 100:\n",
    "                    descriptions.append(m.text)\n",
    "            except NoSuchElementException:\n",
    "                descriptions.append(\" -- \")\n",
    "\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "        for l in price:\n",
    "            try:\n",
    "                if len(prices) != 100:\n",
    "                    prices.append(l.text.split(\"Rs.\")[1])\n",
    "            except NoSuchElementException:\n",
    "                prices.append(\" -- \")     \n",
    "\n",
    "\n",
    "        next_url = driver.find_element_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/div[2]/ul/li[12]/a\")\n",
    "        driver.get(next_url.get_attribute('href'))\n",
    "\n",
    "    sneakers = pd.DataFrame({'Brand' : brands,\n",
    "                                'Descriptions': descriptions,\n",
    "                                'Price (in Rs)': prices})\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return sneakers\n",
    "\n",
    "df = find_shoes(\"https://www.myntra.com/shoes\")\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "Q10: Go to webpage https://www.amazon.in/ . Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”. After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop: title, Ratings and Price.\n",
    "    \n",
    "----------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>4</td>\n",
       "      <td>45,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>3</td>\n",
       "      <td>53,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>2</td>\n",
       "      <td>96,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo Legion 5i 10th Gen Intel Core...</td>\n",
       "      <td>1</td>\n",
       "      <td>76,492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7 14-inch ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1,00,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>74,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI GF63 Thin, Intel 10th Gen. i7-10750H, 15.6...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>63,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating      Price\n",
       "0  (Renewed) Dell Latitude E6420 14 Inch Laptop (...       4    45,000\n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...       3    53,999\n",
       "2  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...       2    96,000\n",
       "3  (Renewed) Lenovo Legion 5i 10th Gen Intel Core...       1    76,492\n",
       "4  Lenovo Yoga 7i 11th Gen Intel Core i7 14-inch ...     4.2  1,00,999\n",
       "5  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...     3.3    74,490\n",
       "6  MSI GF63 Thin, Intel 10th Gen. i7-10750H, 15.6...     3.5    92,990\n",
       "7  (Renewed) Dell Latitude E7470 14-inch Laptop (...     3.8    63,599\n",
       "8  (Renewed) Dell Latitude E6420 14 Inch Laptop (...     2.5    35,000\n",
       "9  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...     3.4    74,990"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_laptops(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    search = driver.find_element_by_xpath(\"//input[@id='twotabsearchtextbox']\")\n",
    "    search.send_keys(\"Laptop\")\n",
    "\n",
    "\n",
    "    search = driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "    try:\n",
    "        search.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #Filter : CPU - Intel Core i7\n",
    "        filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "        for i in filter_button:\n",
    "            if i.text=='Intel Core i7':\n",
    "                i.click()\n",
    "                break\n",
    "        \n",
    "      \n",
    "        #Filter : CPU - Intel Core i9\n",
    "        filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "        for i in filter_button:\n",
    "            if i.text=='Intel Core i9':\n",
    "                i.click()\n",
    "                break\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "\n",
    "\n",
    "\n",
    "    titles = []\n",
    "    ratings = []\n",
    "    prices = []\n",
    "   \n",
    "    \n",
    "    title = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    for j in range(0,len(title)):\n",
    "        try:\n",
    "            if len(titles) != 10:\n",
    "                titles.append(title[j].text)\n",
    "        except NoSuchElementException:\n",
    "            titles.append(\" -- \")\n",
    "\n",
    "    rating = driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "    for k in range(0,len(rating)):\n",
    "        try:\n",
    "            if len(ratings) != 10:\n",
    "                ratings.append(rating[k].get_attribute('innerHTML').split(\" \")[0])\n",
    "        except NoSuchElementException:\n",
    "            ratings.append(\" -- \")\n",
    "\n",
    "    price = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "    for l in range(0,len(price)):\n",
    "        try:\n",
    "            if len(prices) != 10:\n",
    "                prices.append(price[l].get_attribute('innerHTML'))\n",
    "        except NoSuchElementException:\n",
    "            prices.append(\" -- \")\n",
    "\n",
    "    \n",
    "    \n",
    "    laptops = pd.DataFrame({\"Title\" : titles,\n",
    "                            'Rating ' : ratings,\n",
    "                            'Price' : prices                                      \n",
    "                            })\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "    return laptops\n",
    "\n",
    "\n",
    "df = find_laptops(\"https://www.amazon.in/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location from https://www.glassdoor.co.in/index.htm .You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Job Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WishFin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JNtech Networks</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QuantumIT</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSD Consultant</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adidas</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company Rating Job Posted\n",
       "0                       WishFin    4.0          2\n",
       "1  Salasar New Age Technologies    4.4          3\n",
       "2               JNtech Networks    3.3          4\n",
       "3                     QuantumIT    3.7          2\n",
       "4                WSD Consultant    4.2          3\n",
       "5                Biz2Credit Inc    4.0          3\n",
       "6                     dunnhumby    3.7          3\n",
       "7                        adidas    3.9          3\n",
       "8                     HDFC Bank    4.2          7\n",
       "9                      Ericsson    3.0          2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_jobs_from(url):\n",
    "    driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(10\n",
    "    current_url = driver.current_url\n",
    "    driver.get(current_url)\n",
    "    #search page\n",
    "    skill_field = driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "    skill_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "    location_field = driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "    location_field.send_keys(Keys.CONTROL + \"a\")\n",
    "    location_field.send_keys(Keys.DELETE)\n",
    "    location_field.send_keys(\"Noida\")\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@data-test='search-bar-submit']\")\n",
    "    try:\n",
    "        search_button.click()\n",
    "    except ElementNotInteractableException:\n",
    "        print(\"Search button Not responding!!\")\n",
    "        \n",
    "    time.sleep(0.5)\n",
    "\n",
    "\n",
    "\n",
    "    companies = []\n",
    "    ratings = []\n",
    "    days = []\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "            \n",
    "    companies = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a[1]/span\")\n",
    "    company_name = []\n",
    "    for i in companies:\n",
    "        if i.text is None :\n",
    "            company_name.append(\"--\") \n",
    "        else:\n",
    "            company_name.append(i.text)\n",
    "\n",
    "   \n",
    "    ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "    company_ratings=[]\n",
    "    for i in ratings:\n",
    "        if i.text is None :\n",
    "            company_ratings.append(\"--\") \n",
    "        else:\n",
    "            company_ratings.append(i.text)\n",
    "\n",
    "   \n",
    "            \n",
    "    days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    days_ago = []\n",
    "    for i in days:\n",
    "        if i.text is None :\n",
    "            days_ago.append(\"--\") \n",
    "        else:\n",
    "            days_ago.append(i.text[0])\n",
    "  \n",
    "    \n",
    "\n",
    "    data_scientist_jobs = pd.DataFrame({'Company' : company_name[0:10],\n",
    "                                      'Rating' : company_ratings[0:10],\n",
    "                                      'Job Posted' : days_ago[0:10]\n",
    "                                      \n",
    "                                 })\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "    return data_scientist_jobs\n",
    "    \n",
    "    \n",
    "\n",
    "df = find_jobs_from(\"https://www.glassdoor.co.in/index.htm\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
